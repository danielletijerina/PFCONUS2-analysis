{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac164e-65d3-4737-a52d-11b9c2855b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make CSV of CONUS2 flow at matched gages ###\n",
    "### DTT, 10/22\n",
    "\n",
    "# This script is split into two main parts: 1) reading in CONUS2 gridded total (aggregated) daily flow for the full domain and creating a dataframe of CONUS2 flow for cells that have been matched with USGS gages in the `NWM_Gage_Adjustments_final.csv`. 2) matching the gages that both have flow between the PF csv and USGS csv retrieved from hydrodata. \n",
    "# Note that flow is converted in this script from daily accumulated flow in [m^3/h] to daily mean flow in cms or [m^3/s].\n",
    "\n",
    "### Inputs:\n",
    "# - `NWM_Gage_Adjustments_final.csv` - this can be found on the CONUS2 Dropbox or in /glade/p/univ/ucsm0002/CONUS2/domain_files\n",
    "# - Daily total streamflow PFCLM outputs as PFBs - processed using `compute_daily_PF_averages.py`\n",
    "# - USGS daily flow csv - from the hydrodata repository on Verde\n",
    "\n",
    "### Outputs:\n",
    "# - CSV of PFCLM daily mean flow (cms) with gage ID, lat/long, and CONUS2 cell location\n",
    "# - two flow-matched CSVs for PF and USGS flow\n",
    "# - note that the CSV outputs with 'day 001' which starts at the water year (001 == October 1)***\n",
    "\n",
    "# Notes:\n",
    "# - need to fix the no_days, currently this will only be accurate if this is started at the begninning of a water year and need to add in some dictionary or if statement to specify num days in a month or something like that.\n",
    "# - ***need to change day headings so that they are more descriptive than 'day 001' and have an actual date\n",
    "\n",
    "import sys\n",
    "from parflow.tools.io import read_pfb,write_pfb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Directory where PF flow PFBs are saved in\n",
    "directory_out = '/glade/scratch/tijerina/CONUS2/spinup_WY2003/averages'\n",
    "organized_dir = '/glade/p/univ/ucsm0002/CONUS2/Validation/Streamflow/Organized_Daily_Flow'\n",
    "\n",
    "usgs_data = 'USGS_WY2003_oct_mean_flow.csv' #csv of USGS flow from hydrodata\n",
    "\n",
    "# need to change water year and number of days\n",
    "water_year = 2003\n",
    "no_days = 31 \n",
    "\n",
    "### check gage locations for daily flow\n",
    "NWM_gage_csv = pd.read_csv('/glade/p/univ/ucsm0002/CONUS2/domain_files/NWM_Gage_Adjustments_final.csv')\n",
    "\n",
    "\n",
    "### set up pandas dataframe of gage ID, lat/long, CONUS2 x and y indices ###\n",
    "pf_flow_df = pd.DataFrame(columns = ['STNID', 'USGS_lat', 'USGS_lon', 'x_new_adj', 'y_new_adj'])\n",
    "pf_flow_df['STNID'] = NWM_gage_csv['STNID'].astype(int)\n",
    "pf_flow_df['USGS_lat'] = NWM_gage_csv['USGS_lat']\n",
    "pf_flow_df['USGS_lon'] = NWM_gage_csv['USGS_lon']\n",
    "pf_flow_df['x_new_adj'] = NWM_gage_csv['x_new_adj']\n",
    "pf_flow_df['y_new_adj'] = NWM_gage_csv['y_new_adj']\n",
    "\n",
    "# add leading zeros to USGS gages\n",
    "pf_flow_df['STNID'] = pf_flow_df['STNID'].astype('str').str.zfill(8)\n",
    "\n",
    "\n",
    "### READ STREAMFLOW PFBs ###\n",
    "# Read in CONUS2 daily streamflow PFBs and save as df in flow_df, convert to total accumulated in m^3/h to mean daily in cms\n",
    "for i in range(no_days):\n",
    "    step = str(int(i+1)).rjust(3, '0')\n",
    "    pf_flow_pfb = np.squeeze(read_pfb(f'{directory_out}/flow.2003.daily.{step}.pfb'))\n",
    "    pf_flow_df[f'day {step}'] = pf_flow_pfb[pf_flow_df['y_new_adj'],pf_flow_df['x_new_adj']]/3600/24 # CONVERT FROM m^3/h to cms AND from daily accumulated to daily mean\n",
    "    print(f'reading flow for day {step} and converting from total accumulated flow in m^3/h, to daily mean flow in cms')\n",
    "\n",
    "    \n",
    "# Create column for matching/have flow (=1) and not matching/have no flow (=0) gages\n",
    "pf_flow_df['matched'] = np.where(pf_flow_df['day 001']>0, 1, 0)\n",
    "\n",
    "# remove cells with no flow and make new pandas df with matching flow at CONUS2 cells and USGS gages\n",
    "pf_flow_df_NWM_match = pf_flow_df[pf_flow_df.matched != 0]\n",
    "\n",
    "# SAVE OUT PANDAS DF FOR CONUS2 FLOW\n",
    "### save csv file of all matching gage locations and CONUS2 daily flow, note the USGS STNID's drop the leading zeros when saving\n",
    "pf_flow_df_NWM_match.to_csv(f'{organized_dir}/CONUS2_NWM_matched_flow_{water_year}.csv', sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f079219-a303-400f-b600-b7a3ff08d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### read in csv that was just created of gage locations and CONUS2 flow\n",
    "pf_flow_df = pd.read_csv(f'{organized_dir}/CONUS2_NWM_matched_flow_{water_year}.csv',index_col=['STNID'])\n",
    "pf_flow_df = pf_flow_df.drop(columns=['Unnamed: 0','USGS_lat','USGS_lon','x_new_adj','y_new_adj','matched']) #drop unnecessary columns for now\n",
    "pf_flow_df.index.names = ['site_id']\n",
    "                          \n",
    "### read in USGS flow for all gages with flow in October\n",
    "# streamflow from hydrodata has already been converted to cms!!!\n",
    "usgs_flow_df = pd.read_csv(f'{organized_dir}/{usgs_data}',index_col=['site_id']) \n",
    "usgs_flow_df = usgs_flow_df.drop(columns=['Unnamed: 0', 'num_obs'])\n",
    "                          \n",
    "# merge the CONUS2 and USGS dataframes so that we remove all gage locations that don't match between the two\n",
    "combine_df = pf_flow_df.merge(usgs_flow_df, on='site_id', how='inner')\n",
    "                    \n",
    "#********* FIX these next lines, the dates are hardcoded in ************\n",
    "# separate the CONUS2 flow from the USGS flow in the combine_df\n",
    "pf_flow_matched = pd.DataFrame(combine_df.iloc[:,0:31]) # get only CONUS2 flow\n",
    "usgs_flow_matched = pd.DataFrame(combine_df.iloc[:,31:62]) #get only USGS flow \n",
    "                          \n",
    "# Save Flow Matched CSVs\n",
    "pf_flow_matched.to_csv(f'{organized_dir}/CONUS2_daily_FlowMatch_cms_{water_year}.csv', sep = \",\")\n",
    "usgs_flow_matched.to_csv(f'{organized_dir}/USGS_daily_FlowMatch_cms_{water_year}.csv', sep = \",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:parflow-npl]",
   "language": "python",
   "name": "conda-env-parflow-npl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
