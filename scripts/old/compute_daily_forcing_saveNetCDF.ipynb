{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fe94c7-8f8c-46f6-a5ef-3c8d008e0fe9",
   "metadata": {},
   "source": [
    "### Save NLDAS forcing daily averages\n",
    "This script takes hourly NLDAS forcing variables as PFB files (saved on Verde) and computes the daily, (monthly, and yearly) average to save as a NetCDF files.\n",
    "\n",
    "Inputs:\n",
    "- Directory where forcing is and directory where you want to save output\n",
    "- Hourly PFB files of NLDAS3 forcing\n",
    "- water year and day start/end\n",
    "- variable that you want to compute and save averages for:  \n",
    "['Temp', 'APCP', 'DLWR', 'DSWR', 'Press', 'SPFH', 'UGRD', 'VGRD']\n",
    "\n",
    "Outputs:\n",
    "- NetCDF files for daily average of each variable\n",
    "\n",
    "Notes (10/7/22):\n",
    "- Need to determine when is the daily start and end for US time zone, NLDAS3 forcing is UTC\n",
    "- Need to add in monthly and yearly averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17adc139-8e5e-4c5d-bcae-d4b39f83e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from parflow import Run\n",
    "import sys\n",
    "from parflow.tools.io import read_pfb,write_pfb\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606c96c1-f93f-4543-8245-8a6103b5de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#these 3 entries (year, day start and day end) will eventually be argv to the script so that it can be run from bash script\n",
    "water_year = 2003\n",
    "day_start = 0 #day_start = 0 is the first day of the water year, Oct 1 or 000001_000024\n",
    "day_end = 2 #day_end = 364 is the final day of the water year, Sept 30 or 008737_to_008760\n",
    "\n",
    "#list of forcing variables you want\n",
    "variables_forcing = ['Temp']\n",
    "#indication whether you want the mean (1) or the sum (0)\n",
    "variables_forcing_mean = [1]\n",
    "\n",
    "# directory where hourly forcing files are located\n",
    "directory_in_forcing = f'/glade/p/univ/ucsm0002/CONUS2/Forcing'\n",
    "\n",
    "# directory to save averages to\n",
    "directory_out_forcing = f'/glade/scratch/tijerina/NLDAS_averages/WY{water_year}'\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd5ec60-264e-4822-925e-109c3ae77e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### READING ALL STATIC VARIABLES NEEDED\n",
    "# nz = 10\n",
    "# ny = 3256\n",
    "# nx = 4442\n",
    "\n",
    "# dx = 1000\n",
    "# dy = 1000\n",
    "# dz = 200\n",
    "\n",
    "# #apparently it's good to use high numbers when saving files to speed up reading?\n",
    "\n",
    "# ### DO WE NEED THIS? Think we can just submit as a serial process\n",
    "# ### ALSO, aren't the p, q, r for the dist here? which is set to False\n",
    "# p = 48\n",
    "# q = 36\n",
    "# r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325a8d8a-098b-4e8f-bef4-57b2669bc042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/tijerina/conda-envs/parflow-npl/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to  /glade/scratch/tijerina/NLDAS_averages/WY2003/NLDAS.Temp.daily.001.nc\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_netcdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/glade/scratch/tijerina/ipykernel_161206/1566510477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnc_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{directory_out_forcing}/NLDAS.{var}.daily.{timestamp_day_out}.nc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'saving to '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnc_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mforcing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_netcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnc_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'finished saving'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_netcdf'"
     ]
    }
   ],
   "source": [
    "for day in range(day_start,day_end):\n",
    "\n",
    "    timestamp_day_out = str(int(day+1)).rjust(3, '0')\n",
    "\n",
    "    #READING FORCING VARIABLES\n",
    "    #timestamps beginning and ending of the day\n",
    "    h_start_forcing = str(int(day*24+1)).rjust(6, '0')\n",
    "    h_end_forcing = str(int((day+1)*24)).rjust(6, '0')\n",
    "    \n",
    "    #looping through the forcing variables you want an average for\n",
    "    for ind_forcing in range(len(variables_forcing)):\n",
    "        var=variables_forcing[ind_forcing]\n",
    "        forcing = read_pfb(f'{directory_in_forcing}/WY{water_year}/NLDAS.{var}.{h_start_forcing}_to_{h_end_forcing}.pfb')\n",
    "        #sum over the 24h and divide by 24\n",
    "        if variables_forcing_mean[ind_forcing]==1:\n",
    "            forcing = np.sum(forcing,axis=0)/24\n",
    "        \n",
    "        \n",
    "        \n",
    "        ######### TRY THIS!!!\n",
    "        df = xr.DataArray(Data, coords=[('lon', longitude), ('lat', latitude)])\n",
    "        df.to_netcdf('filename.nc')\n",
    "        ############# https://stackoverflow.com/questions/59734176/save-np-array-to-netcdf4-files-with-python\n",
    "        \n",
    "        nc_filename = f'{directory_out_forcing}/NLDAS.{var}.daily.{timestamp_day_out}.nc'\n",
    "        print ('saving to ', nc_filename)\n",
    "        forcing.to_netcdf(path=nc_filename)\n",
    "        print ('finished saving')\n",
    "\n",
    "        #write_pfb(f'{directory_out_forcing}/NLDAS.{var}.daily.{timestamp_day_out}.pfb',forcing,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "        #print(f'Saving {var}: day {timestamp_day_out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d27da-6f28-442e-952e-32443e85e94a",
   "metadata": {},
   "source": [
    "# How to save pfbs so they are only 2D??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80fdf947-922a-481c-89ac-d3006b56edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_Temp = np.squeeze(read_pfb(f'{directory_out_forcing}/NLDAS.Temp.daily.001.pfb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da176eec-3002-4cf4-8b8e-bd7bc9f62c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3256, 4442)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1_Temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6c270e1-7f53-4aa3-ace8-a3681df8340d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        -inf,         -inf,         -inf,         -inf,\n",
       "                -inf],\n",
       "       [        -inf, 301.00572713, 300.99767431, 300.99038315,\n",
       "                -inf],\n",
       "       [301.02525457, 301.01606623, 301.00750351, 301.00183741,\n",
       "        301.00152079],\n",
       "       [301.03162511, 301.02574412, 301.01710002, 301.00990168,\n",
       "        301.00638072],\n",
       "       [301.02079391, 301.01398849, 301.00410843, 300.99659348,\n",
       "        300.99309667]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1_Temp[103:108,2185:2190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201859c-c600-41ff-aafb-7f4113bcdd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:parflow-npl]",
   "language": "python",
   "name": "conda-env-parflow-npl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
