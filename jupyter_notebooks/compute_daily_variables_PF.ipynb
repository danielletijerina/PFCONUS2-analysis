{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7a3bee-d656-4268-9209-c77b1d27af64",
   "metadata": {},
   "source": [
    "### Process and save ParFlow daily averages\n",
    "This script takes hourly PF outputs as PFB files and computes the daily averages to be saved as PFB files.\n",
    "\n",
    "Inputs:\n",
    "- Directory where PF outputs are and directory where you want to save output\n",
    "- Hourly PFB files of PF outputs\n",
    "- water year and day start/end\n",
    "\n",
    "Outputs:\n",
    "- PFB files for daily average of each variable:  \n",
    "    - Overland flow at each grid cell (flow)\n",
    "    - Soil moisture (SM)\n",
    "    - Water table depth (WTD)\n",
    "\n",
    "  - _Subsurface Storage_\n",
    "    - Total Subsurface Storage (SUBstorage)\n",
    "    - GW storage (GWstorage)\n",
    "    - Soil moisture storage (SMstorage)\n",
    "\n",
    "  - _Total Water Storage_\n",
    "    - Surface water storage (SURF_WATstorage)\n",
    "    - Total water storage (TWS)\n",
    "    \n",
    "Notes (10/21/22):\n",
    "- Need to determine when is the daily start and end for US time zone, NLDAS3 forcing is UTC\n",
    "- Need to add in monthly and yearly averages - Created new script for this since we are processing one month at a time `Compute_month-year_averages_PFCLM.ipynb`\n",
    "- ADD UNITS OF CALCULATIONS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17adc139-8e5e-4c5d-bcae-d4b39f83e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from parflow import Run\n",
    "import sys\n",
    "from parflow.tools.io import read_pfb,write_pfb\n",
    "import parflow.tools.hydrology as hydro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606c96c1-f93f-4543-8245-8a6103b5de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NCLMOUTPUTS = 13 + 4 #13 (number variables) + number of layers over which CLM is active, NZ root\n",
    "\n",
    "#these 3 entries (year, day start and day end) will eventually be argv to the script so that it can be run from bash script\n",
    "water_year = 2003\n",
    "day_start = 1 #day_start = 0 is the first day of the water year, Oct 1 (e.g., day_start = 2 starts at hour 49)\n",
    "day_end = 3 #day_end = 364 is the final day of the water year, Sept 30\n",
    "\n",
    "# water_year = int(sys.argv[1])\n",
    "# day_start = int(sys.argv[1])\n",
    "# day_end = int(sys.argv[1])\n",
    "\n",
    "# path to PF outputs outputs\n",
    "path_outputs = '/glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/' #f'/WY{water_year}/'\n",
    "\n",
    "# PFCLM run name\n",
    "runname = 'spinup.wy2003' #f'CONUS2_{water_year}'\n",
    "\n",
    "# directory to save averages to\n",
    "directory_out = f'/glade/scratch/tijerina/CONUS2/spinup_WY2003/averages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ded1750-43fc-4958-a9fb-92ed0e1b630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: Field BinaryOutDir is not part of the expected schema <class 'parflow.tools.database.generated.Solver'>\n",
      "Solver.OverlandKinematic: Field SeepageOne is not part of the expected schema <class 'parflow.tools.database.generated.OverlandKinematic'>\n",
      "Solver.OverlandKinematic: Field SeepageTwo is not part of the expected schema <class 'parflow.tools.database.generated.OverlandKinematic'>\n",
      " => Error during CLM import - CLM specific key have been skipped\n"
     ]
    }
   ],
   "source": [
    "run = Run.from_definition(f'{path_outputs}/{runname}.pfidb')\n",
    "data = run.data_accessor\n",
    "\n",
    "porosity = data.computed_porosity \n",
    "specific_storage = data.specific_storage \n",
    "mannings = data.mannings\n",
    "\n",
    "## remove input filenames for TopoSlopes to force the data accessor to read the output slopes\n",
    "## this fixes a windows issue\n",
    "run.TopoSlopesX.FileName = None\n",
    "run.TopoSlopesY.FileName = None\n",
    "\n",
    "slopex = data.slope_x \n",
    "slopey = data.slope_y \n",
    "mask = data.mask\n",
    "\n",
    "# formatting the mask so that values outside the domain are NA and inside the domain are 1\n",
    "# check with mask that has 0 and 1\n",
    "active_mask=mask.copy()\n",
    "active_mask[active_mask > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd5ec60-264e-4822-925e-109c3ae77e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###READING ALL STATIC VARIABLES NEEDED\n",
    "# Read in porosity data\n",
    "#porosity = read_pfb(f'{path_outputs}{runname}.out.porosity.pfb')\n",
    "#...\n",
    "#etc.\n",
    "\n",
    "#nz,ny,nx = porosity.shape()\n",
    "\n",
    "nz = 10\n",
    "ny = 3256\n",
    "nx = 4442\n",
    "\n",
    "dx = 1000\n",
    "dy = 1000\n",
    "dz = 200\n",
    "dz_3d = data.dz\n",
    "\n",
    "# apparently it's good to use high numbers when saving files to speed up reading?\n",
    "# for write_pfb function\n",
    "p = 72\n",
    "q = 48\n",
    "r = 1\n",
    "\n",
    "# #list of clm variables you want\n",
    "# variables_clm = ['eflx_lh_tot','qflx_evap_grnd','qflx_tran_veg','swe_out','t_grnd','t_soil']\n",
    "# #indication whether you want the mean (1) or the sum (0)\n",
    "# variables_clm_mean = [0,0,0,1,1,1]\n",
    "\n",
    "# ALL_CLM = ['eflx_lh_tot','eflx_lwrad_out','eflx_sh_tot','eflx_soil_grnd','qflx_evap_tot','qflx_evap_grnd','qflx_evap_soi','qflx_evap_veg','qflx_tran_veg','qflx_infl','swe_out','t_grnd','qflx_qirr','t_soil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a1d51db-71f1-41ed-bfc2-65239e647328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3256, 4442)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porosity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e9e295-3ecc-4796-ad15-6d59b04235b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3256, 4442)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325a8d8a-098b-4e8f-bef4-57b2669bc042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00049\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00050\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00051\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00052\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00053\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00054\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00055\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00056\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00057\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00058\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00059\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00060\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00061\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00062\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00063\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00064\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00065\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00066\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00067\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00068\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00069\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00070\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00071\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00072\n"
     ]
    }
   ],
   "source": [
    "for day in range(day_start,day_end):\n",
    "\n",
    "    timestamp_day_out = str(int(day+1)).rjust(3, '0')\n",
    "\n",
    "    ##INITIALIZE WHATEVER DYNAMIC VARIABLES THAT NEED HOURLY READING\n",
    "    overland_flow = np.zeros((ny, nx)) # Flow\n",
    "    soil_moisture = np.zeros((nz,ny,nx)) # Soil Moisture\n",
    "    wtd = np.zeros((ny, nx)) # Water Table Depth\n",
    "    \n",
    "    surface_storage = np.zeros((ny,nx)) # Surface Water Storage\n",
    "    \n",
    "    # Subsurface Storage Components\n",
    "    subsurface_storage = np.zeros((nz,ny,nx)) # Total Subsurface Storage\n",
    "    gw_storage = np.zeros((nz,ny,nx)) # Groundwater Storage\n",
    "    sm_storage = np.zeros((nz,ny,nx)) # Soil Moisture Storage\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #if not variables_clm == False:\n",
    "    #    clm_output = np.zeros((NCLMOUTPUTS,ny,nx))\n",
    "    for h in range(day*24+1,(day+1)*24+1):\n",
    "        #### I *THINK* that to average these for CONUS (so assuming UTC-6), this would change to range(day*24+1+6,(day+1)*24+1+6):\n",
    "        timestamp_reading = str(int(h)).rjust(5, '0')\n",
    "        \n",
    "        #read pressure and saturation at timestep \n",
    "        saturation = read_pfb(f'{path_outputs}{runname}.out.satur.{timestamp_reading}.pfb') * active_mask\n",
    "        pressure = read_pfb(f'{path_outputs}{runname}.out.press.{timestamp_reading}.pfb') * active_mask\n",
    "        print(f'reading {path_outputs}{runname}.out at time {timestamp_reading}')\n",
    "        \n",
    "        ################### \n",
    "        # Computations\n",
    "        ###################\n",
    "        # Flow [m^3/h]\n",
    "        overland_flow = hydro.calculate_overland_flow_grid(pressure, slopex, slopey, mannings, dx, dy, mask = active_mask)\n",
    "        #Soil Moisture\n",
    "        soil_moisture += saturation * porosity\n",
    "        # Water Table Depth\n",
    "        wtd = hydro.calculate_water_table_depth(pressure, saturation, dz_3d)\n",
    "        \n",
    "        # Surface Storage\n",
    "        ## total surface storage for this time step is the summation of substorage surface across all x/y slices <-- from other script, is this still TRUE??\n",
    "        surface_storage += hydro.calculate_surface_storage(pressure, dx, dy, mask = active_mask)\n",
    "        \n",
    "        # Total Subsurface Storage\n",
    "        subsurface_storage += hydro.calculate_subsurface_storage(porosity, pressure, saturation, specific_storage, dx, dy, dz_3d, mask = active_mask)\n",
    "        \n",
    "        # Groundwater Storage\n",
    "        #gw_storage +=\n",
    "        \n",
    "        # Soil Moisture Storage\n",
    "        #sm_storage +=\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        #CLM Variables\n",
    "        #clm_output += read_pfb(f'{path_outputs}{runname}.out.clm_output.{timestamp_reading}.C.pfb')\n",
    "\n",
    "    ### compute average for average variables\n",
    "    overland_flow /= 24\n",
    "    soil_moisture /= 24\n",
    "    wtd /= 24 # CHANGE THIS TO BE ACCUMULATED?? 10/7/22\n",
    "    \n",
    "    surface_storage /= 24\n",
    "    \n",
    "    subsurface_storage /= 24\n",
    "    #gw_storage /= 24\n",
    "    #sm_storage /= 24\n",
    "\n",
    "\n",
    "    subsurface[active_mask==0]=-10**(38) ### ???????????\n",
    "    \n",
    "    ### SAVE VARIABLES AS PFB FILES\n",
    "    write_pfb(f'{directory_out}/flow.{water_year}.daily.{timestamp_day_out}.pfb',overland_flow,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/SM.{water_year}.daily.{timestamp_day_out}.pfb',soil_moisture,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/WTD.{water_year}.daily.{timestamp_day_out}.pfb',wtd,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/SURF_WATstorage.{water_year}.daily.{timestamp_day_out}.pfb',surface_storage,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/SUBstorage.{water_year}.daily.{timestamp_day_out}.pfb',subsurface_storage,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/GWstorage.{water_year}.daily.{timestamp_day_out}.pfb',gw_storage,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/SMstorage.{water_year}.daily.{timestamp_day_out}.pfb',sm_storage,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd22a21-c475-49c8-a848-343841632f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad73bce-cc03-49b2-8dd0-bf3d428270cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967c8bc-f5f0-49a2-a790-cc985e363c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786073e-e548-4a2a-a5b3-a4f590165951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633056d5-8786-4f92-92ad-737f6b48f834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d5c7f-e5ec-414e-9d05-93e1cb717eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3cc40-5189-4949-a468-eb0c9a6dbbba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230357fd-1790-46e3-b062-f9b7b02487f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_sm = read_pfb(f'{directory_out}/spinup.wy2003.out.SM.001.pfb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84232cc-81ba-4d2c-a398-b1bca0270fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c5fcc1-8691-4414-a84f-b06b04e1a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_sm[9,2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdf947-922a-481c-89ac-d3006b56edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_array = np.squeeze(read_pfb(f'{directory_out}/flow.2003.daily.001.pfb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb0378-8a0b-4e5c-9f6e-eb41744e173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da67d2-8f69-44ff-ad1c-b9bff0bf88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_array.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1a0e2-2261-4ae3-8cef-146c30bdbd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf036fd-60f4-481c-a450-0e2e779a3a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157bcf7c-10a7-4d3a-9d3f-d85e9e85c29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "194b7e20-aefe-44ec-b859-f38e7958d28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file 0\n",
      "reading file 1\n",
      "reading file 2\n",
      "reading file 3\n",
      "reading file 4\n"
     ]
    }
   ],
   "source": [
    "# 4: qflx_evap_tot for total evaporation [mm/s]\n",
    "qflx_evap_CLM = np.zeros((5, ny, nx))\n",
    "for i in range(5):    \n",
    "    print(f'reading file {i}')\n",
    "    CLM_file = read_pfb(f'{path_outputs}/{runname}.out.clm_output.{str(i+1).zfill(5)}.C.pfb')\n",
    "    CLM_file[CLM_file<-9000] = 0 # set values outside of the domain to zero\n",
    "    qflx_evap_CLM[i, ...] = CLM_file[4,...] # fill qflx_evap_CLM array by flagging the 4 position in the CLM file for qflx_evap_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac7e185d-326a-43b7-846a-f39ae589e905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3256, 4442)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert ET from mm/s to mm/h\n",
    "qflx_evap_CLM = qflx_evap_CLM*3600\n",
    "qflx_evap_CLM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92ec064c-6197-4048-8eec-f419a2062bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01368996, -0.00062362, -0.00064269,  0.01355883, -0.00067061],\n",
       "       [-0.00063027, -0.00064082, -0.00064565,  0.01361385, -0.00064218],\n",
       "       [-0.00061999, -0.0006448 , -0.00064711, -0.0006081 , -0.00064518],\n",
       "       [-0.00063097, -0.00064912, -0.00064875, -0.00064578, -0.00064648],\n",
       "       [-0.00064049, -0.00065066, -0.00064876, -0.00064892, -0.00064619]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the first timestep at a location for qflx_evap\n",
    "qflx_evap_CLM[0,2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06d8118f-924c-4d4c-bd74-80a1d2957373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38027669, -0.01732272, -0.01785239,  0.37663422, -0.01862814],\n",
       "       [-0.01750741, -0.01780053, -0.01793485,  0.37816239, -0.01783835],\n",
       "       [-0.01722189, -0.0179112 , -0.01797532, -0.01689159, -0.01792179],\n",
       "       [-0.01752681, -0.01803109, -0.01802073, -0.01793827, -0.01795774],\n",
       "       [-0.01779131, -0.01807393, -0.0180212 , -0.01802567, -0.01794969]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the first timestep at a location\n",
    "day1_ET = np.squeeze(read_pfb(f'{directory_out}/ET.2003.daily.001.pfb'))\n",
    "day1_ET[9,2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "653f8f46-155d-4e59-a6f5-5a85ca560186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3256, 4442)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumET = day1_ET.sum(axis=0)\n",
    "sumET.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13150a04-a553-499f-9cad-be72d4ee22c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1490.68460902,  -67.90504868,  -69.98137281, 1476.4061264 ,\n",
       "         -73.02232083],\n",
       "       [ -68.62904675,  -69.77806435,  -70.30461678, 1482.39656555,\n",
       "         -69.92634035],\n",
       "       [ -67.50982266,  -70.21188456,  -70.46327344,  -66.21504232,\n",
       "         -70.25341397],\n",
       "       [ -68.70510275,  -70.68188807,  -70.64124413,  -70.31800288,\n",
       "         -70.39433259],\n",
       "       [ -69.74195392,  -70.84980775,  -70.64312293,  -70.66063916,\n",
       "         -70.36277345]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumET[2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6427b-d11c-4f55-a72e-9800da301d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469f1de-f26a-47d8-8c03-67d9bd0ed24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: ncfile.close()  # just to be safe, make sure dataset is not already open.\n",
    "except: pass\n",
    "ncfile = Dataset('../../../data/new.nc',mode='w',format='NETCDF4_CLASSIC') \n",
    "print(ncfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d199964a-22b8-480b-b44f-17f184e702c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_dim = ncfile.createDimension('lat', 73)     # latitude axis\n",
    "lon_dim = ncfile.createDimension('lon', 144)    # longitude axis\n",
    "time_dim = ncfile.createDimension('time', None) # unlimited axis (can be appended to).\n",
    "for dim in ncfile.dimensions.items():\n",
    "    print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777bc2b-11e8-4954-a192-340ac3cd50d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:parflow-npl]",
   "language": "python",
   "name": "conda-env-parflow-npl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
