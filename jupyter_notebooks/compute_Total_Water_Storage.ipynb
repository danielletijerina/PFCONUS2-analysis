{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7a3bee-d656-4268-9209-c77b1d27af64",
   "metadata": {},
   "source": [
    "### Compute Total Water Storage from PFCLM outputs\n",
    "\n",
    "## Rewrite this so that it takes surface storage and total subsurface storage (from PF_averages.py / compute_daily_variables_PF.ipynb) and SWE outputs (from CLM_averages.py / compute_daily_variables_CLM.ipynb) and sums for d, m, y averages  \n",
    "**PFTools Python**:  \n",
    "`TWS = ( calculate_subsurface_storage + calculate_surface_storage + SWE (STORAGE?) ) / 24`   \n",
    "AKA (with daily averages):  \n",
    "`TWS = SUBstorage + SURFstorage + SWEstorage`\n",
    "\n",
    "_EL: SWE storage would be swe from clm output * 1000 (mm->m)dxdy_\n",
    "_____\n",
    "\n",
    "This script takes hourly PFCLM outputs as PFB files and computes the daily, (monthly, and yearly) averages to be saved as PFB files.\n",
    "\n",
    "Inputs:\n",
    "- Directory where PFCLM outputs are and directory where you want to save output\n",
    "- Hourly PFB files of PF Pressure and CLM Snow Water Equivalent outputs\n",
    "- water year and day start/end\n",
    "\n",
    "Outputs:\n",
    "- PFB files for daily average of each variable:  \n",
    "    - Overland flow at each grid cell (flow)\n",
    "    - Soil moisture (SM)\n",
    "    - Water table depth (WTD)\n",
    "\n",
    "  - _Subsurface Storage_\n",
    "    - Total Subsurface Storage (SUBstorage)\n",
    "    - GW storage (GWstorage)\n",
    "    - Soil moisture storage (SMstorage)\n",
    "\n",
    "  - _Total Water Storage_\n",
    "    - Surface water storage (SURFstorage)\n",
    "    - Total water storage (TWS)\n",
    "    \n",
    "Notes (10/21/22):\n",
    "- Need to determine when is the daily start and end for US time zone, NLDAS3 forcing is UTC\n",
    "- Need to add in monthly and yearly averages\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17adc139-8e5e-4c5d-bcae-d4b39f83e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from parflow import Run\n",
    "import sys\n",
    "from parflow.tools.io import read_pfb,write_pfb\n",
    "import parflow.tools.hydrology as hydro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606c96c1-f93f-4543-8245-8a6103b5de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NCLMOUTPUTS = 13 + 4 #13 (number variables) + number of layers over which CLM is active, NZ root\n",
    "\n",
    "#these 3 entries (year, day start and day end) will eventually be argv to the script so that it can be run from bash script\n",
    "water_year = 2003\n",
    "day_start = 0 #day_start = 0 is the first day of the water year, Oct 1 (e.g., day_start = 2 starts at hour 49)\n",
    "day_end = 3 #day_end = 364 is the final day of the water year, Sept 30\n",
    "\n",
    "# water_year = int(sys.argv[1])\n",
    "# day_start = int(sys.argv[1])\n",
    "# day_end = int(sys.argv[1])\n",
    "\n",
    "# path to PF outputs outputs\n",
    "path_outputs = '/glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/' #f'/WY{water_year}/'\n",
    "\n",
    "# PFCLM run name\n",
    "runname = 'spinup.wy2003' #f'CONUS2_{water_year}'\n",
    "\n",
    "# directory to save averages to\n",
    "directory_out = f'/glade/scratch/tijerina/CONUS2/spinup_WY2003/averages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ded1750-43fc-4958-a9fb-92ed0e1b630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: Field BinaryOutDir is not part of the expected schema <class 'parflow.tools.database.generated.Solver'>\n",
      "Solver.OverlandKinematic: Field SeepageOne is not part of the expected schema <class 'parflow.tools.database.generated.OverlandKinematic'>\n",
      "Solver.OverlandKinematic: Field SeepageTwo is not part of the expected schema <class 'parflow.tools.database.generated.OverlandKinematic'>\n",
      " => Error during CLM import - CLM specific key have been skipped\n"
     ]
    }
   ],
   "source": [
    "run = Run.from_definition(f'{path_outputs}/{runname}.pfidb')\n",
    "data = run.data_accessor\n",
    "\n",
    "porosity = data.computed_porosity \n",
    "specific_storage = data.specific_storage \n",
    "mannings = data.mannings\n",
    "\n",
    "## remove input filenames for TopoSlopes to force the data accessor to read the output slopes\n",
    "## this fixes a windows issue\n",
    "run.TopoSlopesX.FileName = None\n",
    "run.TopoSlopesY.FileName = None\n",
    "\n",
    "slopex = data.slope_x \n",
    "slopey = data.slope_y \n",
    "mask = data.mask\n",
    "\n",
    "# formatting the mask so that values outside the domain are NA and inside the domain are 1\n",
    "# check with mask that has 0 and 1\n",
    "active_mask=mask.copy()\n",
    "active_mask[active_mask > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dd5ec60-264e-4822-925e-109c3ae77e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###READING ALL STATIC VARIABLES NEEDED\n",
    "# Read in porosity data\n",
    "#porosity = read_pfb(f'{path_outputs}{runname}.out.porosity.pfb')\n",
    "#...\n",
    "#etc.\n",
    "\n",
    "#nz,ny,nx = porosity.shape()\n",
    "\n",
    "nz = 10\n",
    "ny = 3256\n",
    "nx = 4442\n",
    "\n",
    "dx = 1000\n",
    "dy = 1000\n",
    "dz = 200\n",
    "dz_3d = data.dz\n",
    "\n",
    "# apparently it's good to use high numbers when saving files to speed up reading?\n",
    "# for write_pfb function\n",
    "p = 72\n",
    "q = 48\n",
    "r = 1\n",
    "\n",
    "data.time\n",
    "# #list of clm variables you want\n",
    "# variables_clm = ['eflx_lh_tot','qflx_evap_grnd','qflx_tran_veg','swe_out','t_grnd','t_soil']\n",
    "# #indication whether you want the mean (1) or the sum (0)\n",
    "# variables_clm_mean = [0,0,0,1,1,1]\n",
    "\n",
    "# ALL_CLM = ['eflx_lh_tot','eflx_lwrad_out','eflx_sh_tot','eflx_soil_grnd','qflx_evap_tot','qflx_evap_grnd','qflx_evap_soi','qflx_evap_veg','qflx_tran_veg','qflx_infl','swe_out','t_grnd','qflx_qirr','t_soil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a1d51db-71f1-41ed-bfc2-65239e647328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3256, 4442)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porosity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e9e295-3ecc-4796-ad15-6d59b04235b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3256, 4442)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325a8d8a-098b-4e8f-bef4-57b2669bc042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00049\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00050\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00051\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00052\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00053\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00054\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00055\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00056\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00057\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00058\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00059\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00060\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00061\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00062\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00063\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00064\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00065\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00066\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00067\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00068\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00069\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00070\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00071\n",
      "reading /glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/output-pf/spinup.wy2003.out at time 00072\n"
     ]
    }
   ],
   "source": [
    "for day in range(day_start,day_end):\n",
    "\n",
    "    timestamp_day_out = str(int(day+1)).rjust(3, '0')\n",
    "\n",
    "    ##INITIALIZE WHATEVER DYNAMIC VARIABLES THAT NEED HOURLY READING\n",
    "    overland_flow = np.zeros((ny, nx)) \n",
    "    soil_moisture = np.zeros((nz,ny,nx))\n",
    "    wtd = np.zeros((ny, nx)) \n",
    "    \n",
    "    # Subsurface Storage Components\n",
    "    subsurface_storage = np.zeros((nz,ny,nx)) # Total Subsurface Storage\n",
    "    \n",
    "    # Total Water Storage Components\n",
    "    surface_storage = np.zeros((ny,nx)) \n",
    "    \n",
    "    \n",
    "    #if not variables_clm == False:\n",
    "    #    clm_output = np.zeros((NCLMOUTPUTS,ny,nx))\n",
    "    for h in range(day*24+1,(day+1)*24+1):\n",
    "        timestamp_reading = str(int(h)).rjust(5, '0')\n",
    "        \n",
    "        #read pressure and saturation at timestep \n",
    "        saturation = read_pfb(f'{path_outputs}{runname}.out.satur.{timestamp_reading}.pfb') * active_mask\n",
    "#        pressure = read_pfb(f'{path_outputs}{runname}.out.press.{timestamp_reading}.pfb') * active_mask\n",
    "        print(f'reading {path_outputs}{runname}.out at time {timestamp_reading}')\n",
    "        \n",
    "        ################### \n",
    "        # Computations\n",
    "        ###################\n",
    "        \n",
    "        #Soil Moisture\n",
    "        soil_moisture += saturation * porosity\n",
    "        \n",
    "        # Subsurface Storage\n",
    "#        subsurface_storage += hydro.calculate_subsurface_storage(porosity, pressure, saturation, specific_storage, dx, dy, dz_3d, mask = active_mask)\n",
    "        \n",
    "        # Surface Storage\n",
    "        ## total surface storage for this time step is the summation of substorage surface across all x/y slices <-- from other script, is this still TRUE??\n",
    "#        surface_storage += hydro.calculate_surface_storage(pressure, dx, dy, mask = active_mask)\n",
    "        \n",
    "        # Water Table Depth\n",
    "#        wtd = hydro.calculate_water_table_depth(pressure, saturation, dz_3d)\n",
    "        \n",
    "        # Flow [m^3/h]\n",
    "#        overland_flow = hydro.calculate_overland_flow_grid(pressure, slopex, slopey, mannings, dx, dy, mask = active_mask)\n",
    "        \n",
    "        \n",
    "\n",
    "        #CLM Variables\n",
    "        #clm_output += read_pfb(f'{path_outputs}{runname}.out.clm_output.{timestamp_reading}.C.pfb')\n",
    "\n",
    "    ### compute average for average variables\n",
    "    soil_moisture /= 24\n",
    "    subsurface_storage /= 24\n",
    "    surface_storage /= 24\n",
    "    wtd /= 24 # CHANGE THIS TO BE ACCUMULATED?? 10/7/22\n",
    "    overland_flow /= 24\n",
    "\n",
    "\n",
    "    subsurface[active_mask==0]=-10**(38)\n",
    "    ### SAVE VARIABLES AS PFB FILES\n",
    "    write_pfb(f'{directory_out}/SM.{water_year}.daily.{timestamp_day_out}.pfb',soil_moisture,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    # IS THIS 'GWstore' OR IS IT 'storage'\n",
    "    write_pfb(f'{directory_out}/GWstorage.{water_year}.daily.{timestamp_day_out}.pfb',subsurface_storage,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/surf_wat.{water_year}.daily.{timestamp_day_out}.pfb',surface_storage,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/WTd.{water_year}.daily.{timestamp_day_out}.pfb',wtd,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/flow.{water_year}.daily.{timestamp_day_out}.pfb',overland_flow,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd22a21-c475-49c8-a848-343841632f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8c360a5-89f6-4dca-aeab-e630fda1ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    " ### SAVE VARIABLES AS NETCDF FILES\n",
    "try:nc_file.close()  # just to be safe, make sure dataset is not already open.\n",
    "except: pass\n",
    "#nc_filename = f'{directory_out}/SM.{water_year}.daily.{timestamp_day_out}.nc'\n",
    "nc_filename = f'{directory_out}/SM.{water_year}.daily.999.nc'\n",
    "nc_file = nc.Dataset(nc_filename, 'w', format='NETCDF4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c40b237f-254c-4ce8-94dd-f126b0c4eed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): \n",
      "    variables(dimensions): \n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "print(nc_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd1e0f89-19a2-4aa9-9356-33aaea2a6c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dimensions for nc file\n",
    "ny_dim = nc_file.createDimension('ny', ny)\n",
    "nx_dim = nc_file.createDimension('nx', nx)\n",
    "time_dim = nc_file.createDimension('time', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f655803d-b563-4e81-bc46-363717eaab94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ny', <class 'netCDF4._netCDF4.Dimension'>: name = 'ny', size = 3256)\n",
      "('nx', <class 'netCDF4._netCDF4.Dimension'>: name = 'nx', size = 4442)\n",
      "('time', <class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0)\n"
     ]
    }
   ],
   "source": [
    "### DONT NEED THIS PRINT STATEMENT\n",
    "for dim in nc_file.dimensions.items():\n",
    "    print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31880813-7fef-40b3-a3a6-e844ab85e9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data\n"
     ]
    }
   ],
   "source": [
    "nc_file.title='Test Data'\n",
    "print(nc_file.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71df7df3-8591-4feb-96ff-3bcf28cbac90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dimension'> (unlimited): name = 'time', size = 0\n"
     ]
    }
   ],
   "source": [
    "print(time_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e63ef321-8fb7-4c10-a9bc-8e4919476d5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot find dimension time_dim in this group or parent groups",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/glade/work/tijerina/conda-envs/parflow-npl/lib/python3.7/site-packages/netCDF4/utils.py\u001b[0m in \u001b[0;36m_find_dim\u001b[0;34m(grp, dimname)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdimname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dimensions'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/glade/work/tijerina/conda-envs/parflow-npl/lib/python3.7/site-packages/netCDF4/utils.py\u001b[0m in \u001b[0;36m_find_dim\u001b[0;34m(grp, dimname)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'parent'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/glade/scratch/tijerina/ipykernel_130201/991206908.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# add nc variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'time_dim'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# y = nc_file.createVariable('y', 'int', ('y',))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# x = nc_file.createVariable('x', 'int', ('x',))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# value = nc_file.createVariable('value', np.float32, ('time', 'y', 'x',))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.createVariable\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/glade/work/tijerina/conda-envs/parflow-npl/lib/python3.7/site-packages/netCDF4/utils.py\u001b[0m in \u001b[0;36m_find_dim\u001b[0;34m(grp, dimname)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot find dimension %s in this group or parent groups\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdimname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot find dimension time_dim in this group or parent groups"
     ]
    }
   ],
   "source": [
    "# add nc variables\n",
    "time = nc_file.createVariable('time', np.float32, ('time_dim',))\n",
    "# y = nc_file.createVariable('y', 'int', ('y',))\n",
    "# x = nc_file.createVariable('x', 'int', ('x',))\n",
    "# value = nc_file.createVariable('value', np.float32, ('time', 'y', 'x',))\n",
    "# value.units = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cd80c29-a001-4282-bbe5-6876626c85f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'netCDF4' has no attribute 'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/glade/scratch/tijerina/ipykernel_130201/3765415761.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'netCDF4' has no attribute 'close'"
     ]
    }
   ],
   "source": [
    "nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad73bce-cc03-49b2-8dd0-bf3d428270cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967c8bc-f5f0-49a2-a790-cc985e363c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786073e-e548-4a2a-a5b3-a4f590165951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633056d5-8786-4f92-92ad-737f6b48f834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d5c7f-e5ec-414e-9d05-93e1cb717eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3cc40-5189-4949-a468-eb0c9a6dbbba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230357fd-1790-46e3-b062-f9b7b02487f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_sm = read_pfb(f'{directory_out}/spinup.wy2003.out.SM.001.pfb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84232cc-81ba-4d2c-a398-b1bca0270fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c5fcc1-8691-4414-a84f-b06b04e1a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_sm[9,2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdf947-922a-481c-89ac-d3006b56edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_array = np.squeeze(read_pfb(f'{directory_out}/flow.2003.daily.001.pfb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eb0378-8a0b-4e5c-9f6e-eb41744e173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da67d2-8f69-44ff-ad1c-b9bff0bf88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_array.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1a0e2-2261-4ae3-8cef-146c30bdbd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf036fd-60f4-481c-a450-0e2e779a3a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157bcf7c-10a7-4d3a-9d3f-d85e9e85c29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "194b7e20-aefe-44ec-b859-f38e7958d28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file 0\n",
      "reading file 1\n",
      "reading file 2\n",
      "reading file 3\n",
      "reading file 4\n"
     ]
    }
   ],
   "source": [
    "# 4: qflx_evap_tot for total evaporation [mm/s]\n",
    "qflx_evap_CLM = np.zeros((5, ny, nx))\n",
    "for i in range(5):    \n",
    "    print(f'reading file {i}')\n",
    "    CLM_file = read_pfb(f'{path_outputs}/{runname}.out.clm_output.{str(i+1).zfill(5)}.C.pfb')\n",
    "    CLM_file[CLM_file<-9000] = 0 # set values outside of the domain to zero\n",
    "    qflx_evap_CLM[i, ...] = CLM_file[4,...] # fill qflx_evap_CLM array by flagging the 4 position in the CLM file for qflx_evap_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac7e185d-326a-43b7-846a-f39ae589e905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3256, 4442)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert ET from mm/s to mm/h\n",
    "qflx_evap_CLM = qflx_evap_CLM*3600\n",
    "qflx_evap_CLM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92ec064c-6197-4048-8eec-f419a2062bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01368996, -0.00062362, -0.00064269,  0.01355883, -0.00067061],\n",
       "       [-0.00063027, -0.00064082, -0.00064565,  0.01361385, -0.00064218],\n",
       "       [-0.00061999, -0.0006448 , -0.00064711, -0.0006081 , -0.00064518],\n",
       "       [-0.00063097, -0.00064912, -0.00064875, -0.00064578, -0.00064648],\n",
       "       [-0.00064049, -0.00065066, -0.00064876, -0.00064892, -0.00064619]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the first timestep at a location for qflx_evap\n",
    "qflx_evap_CLM[0,2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06d8118f-924c-4d4c-bd74-80a1d2957373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38027669, -0.01732272, -0.01785239,  0.37663422, -0.01862814],\n",
       "       [-0.01750741, -0.01780053, -0.01793485,  0.37816239, -0.01783835],\n",
       "       [-0.01722189, -0.0179112 , -0.01797532, -0.01689159, -0.01792179],\n",
       "       [-0.01752681, -0.01803109, -0.01802073, -0.01793827, -0.01795774],\n",
       "       [-0.01779131, -0.01807393, -0.0180212 , -0.01802567, -0.01794969]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the first timestep at a location\n",
    "day1_ET = np.squeeze(read_pfb(f'{directory_out}/ET.2003.daily.001.pfb'))\n",
    "day1_ET[9,2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "653f8f46-155d-4e59-a6f5-5a85ca560186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3256, 4442)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumET = day1_ET.sum(axis=0)\n",
    "sumET.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13150a04-a553-499f-9cad-be72d4ee22c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1490.68460902,  -67.90504868,  -69.98137281, 1476.4061264 ,\n",
       "         -73.02232083],\n",
       "       [ -68.62904675,  -69.77806435,  -70.30461678, 1482.39656555,\n",
       "         -69.92634035],\n",
       "       [ -67.50982266,  -70.21188456,  -70.46327344,  -66.21504232,\n",
       "         -70.25341397],\n",
       "       [ -68.70510275,  -70.68188807,  -70.64124413,  -70.31800288,\n",
       "         -70.39433259],\n",
       "       [ -69.74195392,  -70.84980775,  -70.64312293,  -70.66063916,\n",
       "         -70.36277345]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumET[2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6427b-d11c-4f55-a72e-9800da301d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469f1de-f26a-47d8-8c03-67d9bd0ed24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: ncfile.close()  # just to be safe, make sure dataset is not already open.\n",
    "except: pass\n",
    "ncfile = Dataset('../../../data/new.nc',mode='w',format='NETCDF4_CLASSIC') \n",
    "print(ncfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d199964a-22b8-480b-b44f-17f184e702c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_dim = ncfile.createDimension('lat', 73)     # latitude axis\n",
    "lon_dim = ncfile.createDimension('lon', 144)    # longitude axis\n",
    "time_dim = ncfile.createDimension('time', None) # unlimited axis (can be appended to).\n",
    "for dim in ncfile.dimensions.items():\n",
    "    print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777bc2b-11e8-4954-a192-340ac3cd50d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:parflow-npl]",
   "language": "python",
   "name": "conda-env-parflow-npl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
