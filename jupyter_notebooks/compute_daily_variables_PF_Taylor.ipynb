{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and save ParFlow daily averages\n",
    "This script takes hourly PF outputs as PFB files and computes the daily averages to be saved as PFB files.\n",
    "\n",
    "Inputs:\n",
    "- Directory where PF outputs are and directory where you want to save output\n",
    "- Hourly PFB files of PF outputs\n",
    "- water year and day start/end\n",
    "\n",
    "Outputs:\n",
    "- PFB files for daily average of each variable:  \n",
    "    - Overland flow at each grid cell (flow)\n",
    "    - Soil moisture (SM)  \n",
    "    - Water table depth (WTD)  \n",
    "    - Surface water storage (SURF_WATstorage)\n",
    "\n",
    "  - _Subsurface Storage Components:_\n",
    "    - Total Subsurface Storage (SUBstorage)\n",
    "    - GW storage (GWstorage)*\n",
    "    - Soil moisture storage (SMstorage)*\n",
    "\n",
    "    \n",
    "Notes (10/21/22):\n",
    "- Need to determine when is the daily start and end for US time zone, NLDAS3 forcing is UTC\n",
    "- Need to add in monthly and yearly averages - Created new script for this since we are processing one month at a time `Compute_month-year_averages_PFCLM.ipynb`\n",
    "- ADD UNITS OF CALCULATIONS!\n",
    "- *Need to figure out the GW and SM Storage (which layers, do we even want to separate by layer, do by WTD???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from parflow import Run\n",
    "import sys\n",
    "from parflow.tools.io import read_pfb,write_pfb\n",
    "import parflow.tools.hydrology as hydro\n",
    "\n",
    "\n",
    "#plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1636b33e79d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#run = Run.from_definition(f'/hydrodata/PFCLM/Taylor/simulations/{water_year}/Taylor_{water_year}.pfidb')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# # #correcting the metfilepath (folder names where changed after Taylor runs, pfidb still have old paths)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetFilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'/hydrodata/PFCLM/Taylor/simulations/{water_year}/NLDAS/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "#NCLMOUTPUTS = 13 + 4 #13 (number variables) + number of layers over which CLM is active, NZ root\n",
    "\n",
    "#these 3 entries (year, day start and day end) will eventually be argv to the script so that it can be run from bash script\n",
    "water_year = 1999\n",
    "day_start = 1 #day_start = 0 is the first day of the water year, Oct 1 (e.g., day_start = 2 starts at hour 49)\n",
    "day_end = 3 #day_end = 365 is the final day of the water year, Sept 30\n",
    "\n",
    "# water_year = int(sys.argv[1])\n",
    "# day_start = int(sys.argv[1])\n",
    "# day_end = int(sys.argv[1])\n",
    "\n",
    "# path to PF outputs \n",
    "#path_outputs = '/glade/scratch/tijerina/CONUS2/spinup_WY2003/run_inputs/' #f'/WY{water_year}/'\n",
    "path_outputs = f'/hydrodata/PFCLM/Taylor/simulations/{water_year}/' #f'/WY{water_year}/'\n",
    "\n",
    "\n",
    "# PFCLM run name\n",
    "runname = f'Taylor_{water_year}' #f'CONUS2_{water_year}'\n",
    "\n",
    "# directory to save averages to\n",
    "#directory_out = f'/glade/scratch/tijerina/CONUS2/spinup_WY2003/averages'\n",
    "directory_out = '/home/dtt2/CONUS2/analysis_scripts/Taylor_test_outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: Field BinaryOutDir is not part of the expected schema <class 'parflow.tools.database.generated.Solver'>\n",
      "Could not find key soil/soil in ['_parent_', '_prefix_', 'Perm', 'Porosity', 'Retardation', 'domaininput', 'indi_input', 'domain', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8', 'b1', 'b2', 'top', 'bottom', 'side']\n",
      "Could not find key soil/soil in ['_parent_', '_prefix_', 'Perm', 'Porosity', 'Retardation', 'domaininput', 'indi_input', 'domain', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8', 'b1', 'b2', 'top', 'bottom', 'side']\n",
      "Could not find key soil/soil in ['_parent_', '_prefix_', 'Perm', 'Porosity', 'Retardation', 'domaininput', 'indi_input', 'domain', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8', 'b1', 'b2', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key soil/soil in ['_parent_', '_prefix_', 'Perm', 'Porosity', 'Retardation', 'domaininput', 'indi_input', 'domain', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8', 'b1', 'b2', 'top', 'bottom', 'side']\n",
      "Could not find key soil/soil in ['_parent_', '_prefix_', 'Perm', 'Porosity', 'Retardation', 'domaininput', 'indi_input', 'domain', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8', 'b1', 'b2', 'top', 'bottom', 'side']\n",
      "Could not find key soil/soil in ['_parent_', '_prefix_', 'Perm', 'Porosity', 'Retardation', 'domaininput', 'indi_input', 'domain', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8', 'b1', 'b2', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Could not find key soil/soil in ['_parent_', '_prefix_', 'Perm', 'Porosity', 'Retardation', 'domaininput', 'indi_input', 'domain', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8', 'b1', 'b2', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Geom.soil.Perm.TensorValX = 1.0d0\n",
      "Could not find key soil/soil in ['_parent_', '_prefix_', 'Perm', 'Porosity', 'Retardation', 'domaininput', 'indi_input', 'domain', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8', 'b1', 'b2', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Geom.soil.Perm.TensorValY = 1.0d0\n",
      "Could not find key soil/soil in ['_parent_', '_prefix_', 'Perm', 'Porosity', 'Retardation', 'domaininput', 'indi_input', 'domain', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8', 'b1', 'b2', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Geom.soil.Perm.TensorValZ = 1.0d0\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.sink.BCPressure.Type = OverlandFlow\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.lake.BCPressure.Type = OverlandFlow\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.lake.BCPressure.Cycle = rainrec\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.ocean.BCPressure.Type = FluxConst\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.sink.BCPressure.Cycle = rainrec\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.ocean.BCPressure.Cycle = constant\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.lake.BCPressure.RefGeom = domain\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.sink.BCPressure.RefGeom = domain\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.lake.BCPressure.RefPatch = bottom\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.ocean.BCPressure.RefGeom = domain\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.sink.BCPressure.RefPatch = bottom\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.ocean.BCPressure.RefPatch = bottom\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.lake.BCPressure.rec.Value = 0.0\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.sink.BCPressure.rec.Value = 0.0\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.lake.BCPressure.rain.Value = -0.05\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.sink.BCPressure.rain.Value = -0.05\n",
      "Could not find key lake/lake in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.lake.BCPressure.alltime.Value = 0.0\n",
      "Could not find key sink/sink in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.sink.BCPressure.alltime.Value = 0.0\n",
      "Could not find key ocean/ocean in ['_parent_', '_prefix_', 'top', 'bottom', 'side']\n",
      "Caution: Using internal store of run to save Patch.ocean.BCPressure.alltime.Value = 0.0\n",
      "Warning: The following CLM variables could not be set:\n",
      "  - nt\n",
      "  - sw_ini\n",
      "  - qflx_tran_vegm\n",
      "  - hkdepth\n",
      "  - wtfact\n",
      "  - trsmx0\n",
      "  - smpmax\n",
      "  - pondmx\n",
      " => Error during CLM import - CLM specific key have been skipped\n"
     ]
    }
   ],
   "source": [
    "run = Run.from_definition(f'{path_outputs}/{runname}.pfidb')\n",
    "\n",
    "# # #correcting the metfilepath (folder names where changed after Taylor runs, pfidb still have old paths)\n",
    "run.Solver.CLM.MetFilePath = f'/hydrodata/PFCLM/Taylor/simulations/{water_year}/NLDAS/'\n",
    "\n",
    "data = run.data_accessor\n",
    "\n",
    "porosity = data.computed_porosity \n",
    "specific_storage = data.specific_storage \n",
    "# ###################################################mannings = data.mannings\n",
    "mannings = run.Mannings.Geom.domain.Value\n",
    "\n",
    "## remove input filenames for TopoSlopes to force the data accessor to read the output slopes\n",
    "## this fixes a windows issue\n",
    "run.TopoSlopesX.FileName = None\n",
    "run.TopoSlopesY.FileName = None\n",
    "\n",
    "slopex = data.slope_x \n",
    "slopey = data.slope_y \n",
    "mask = data.mask\n",
    "\n",
    "# formatting the mask so that values outside the domain are NA and inside the domain are 1\n",
    "# check with mask that has 0 and 1\n",
    "active_mask=mask.copy()\n",
    "active_mask[active_mask > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###READING ALL STATIC VARIABLES NEEDED\n",
    "# Read in porosity data\n",
    "#porosity = read_pfb(f'{path_outputs}{runname}.out.porosity.pfb')\n",
    "#...\n",
    "#etc.\n",
    "\n",
    "#nz,ny,nx = porosity.shape()\n",
    "\n",
    "nz = 5 #10\n",
    "ny = 47 #3256\n",
    "nx = 45 #4442\n",
    "\n",
    "dx = 1000\n",
    "dy = 1000\n",
    "dz = 5 # 200\n",
    "dz_3d = data.dz\n",
    "\n",
    "# apparently it's good to use high numbers when saving files to speed up reading?\n",
    "# for write_pfb function\n",
    "p = 5 #72\n",
    "q = 5 #48\n",
    "r = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in range(day_start,day_end):\n",
    "\n",
    "    timestamp_day_out = str(int(day+1)).rjust(3, '0')\n",
    "\n",
    "    ##INITIALIZE WHATEVER DYNAMIC VARIABLES THAT NEED HOURLY READING\n",
    "    overland_flow = np.zeros((ny, nx)) # Flow\n",
    "    soil_moisture = np.zeros((nz,ny,nx)) # Soil Moisture\n",
    "    wtd = np.zeros((ny, nx)) # Water Table Depth\n",
    "    surface_storage = np.zeros((ny,nx)) # Surface Water Storage\n",
    "    # Subsurface Storage Components\n",
    "    subsurface_storage = np.zeros((nz,ny,nx)) # Total Subsurface Storage\n",
    "    gw_storage = np.zeros((nz,ny,nx)) # Groundwater Storage\n",
    "    sm_storage = np.zeros((nz,ny,nx)) # Soil Moisture Storage\n",
    "\n",
    "    \n",
    "    for h in range(day*24+1,(day+1)*24+1):\n",
    "        #### I *THINK* that to average these for CONUS (so assuming UTC-6), this would change to range(day*24+1+6,(day+1)*24+1+6):\n",
    "        timestamp_reading = str(int(h)).rjust(5, '0')\n",
    "        \n",
    "        #read pressure and saturation at timestep \n",
    "        saturation = read_pfb(f'{path_outputs}{runname}.out.satur.{timestamp_reading}.pfb') * active_mask\n",
    "        pressure = read_pfb(f'{path_outputs}{runname}.out.press.{timestamp_reading}.pfb') * active_mask\n",
    "        print(f'reading {path_outputs}{runname}.out... at time {timestamp_reading}')\n",
    "        \n",
    "        ################### \n",
    "        # Computations\n",
    "        ###################\n",
    "        # Flow [m^3/s] \n",
    "        overland_flow = hydro.calculate_overland_flow_grid(pressure, slopex, slopey, mannings, dx, dy, mask = active_mask)\n",
    "        \n",
    "        #Soil Moisture [-]\n",
    "        soil_moisture += saturation * porosity\n",
    "        \n",
    "        # Water Table Depth\n",
    "        wtd = hydro.calculate_water_table_depth(pressure, saturation, dz_3d)\n",
    "        \n",
    "        # Surface Storage\n",
    "        ## total surface storage for this time step is the summation of substorage surface across all x/y slices <-- from other script, is this still TRUE??\n",
    "        surface_storage += hydro.calculate_surface_storage(pressure, dx, dy, mask = active_mask)\n",
    "        \n",
    "        # Total Subsurface Storage\n",
    "        subsurface_storage += hydro.calculate_subsurface_storage(porosity, pressure, saturation, specific_storage, dx, dy, dz_3d, mask = active_mask)\n",
    "        \n",
    "        # Groundwater Storage (THIS IS ONLY THE BOTTOM LAYER, SHOULD BE CHANGED WRT WTD)\n",
    "        gw_storage += subsurface_storage[0,...]\n",
    "        \n",
    "        # Soil Moisture Storage (THIS IS ONLY THE SUM OF THE TOP 4 LAYERS, SHOULD BE CHANGED WRT WTD)\n",
    "        sm_storage += np.sum(subsurface_storage[1:4,...], axis = 0)\n",
    "\n",
    "               \n",
    "    ### compute average for average variables ###\n",
    "    # note: flow is ACCUMULATED, so no need to average here\n",
    "    soil_moisture /= 24\n",
    "    wtd /= 24 \n",
    "    surface_storage /= 24\n",
    "    subsurface_storage /= 24\n",
    "    gw_storage /= 24\n",
    "    sm_storage /= 24\n",
    "\n",
    "    #subsurface[active_mask==0]=-10**(38) ### ???????????\n",
    "    \n",
    "    ### SAVE VARIABLES AS PFB FILES\n",
    "    write_pfb(f'{directory_out}/flow.{water_year}.daily.{timestamp_day_out}.pfb',overland_flow,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/SM.{water_year}.daily.{timestamp_day_out}.pfb',soil_moisture,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/WTD.{water_year}.daily.{timestamp_day_out}.pfb',wtd,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/SURF_WATstorage.{water_year}.daily.{timestamp_day_out}.pfb',surface_storage,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/SUBstorage.{water_year}.daily.{timestamp_day_out}.pfb',subsurface_storage,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/GWstorage.{water_year}.daily.{timestamp_day_out}.pfb',gw_storage,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    write_pfb(f'{directory_out}/SMstorage.{water_year}.daily.{timestamp_day_out}.pfb',sm_storage,dx=dx,dy=dy,dz=dz,P=p,Q=q,R=r,dist=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just checking some things down below here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(10):\n",
    "    x = str(int(h+1)).rjust(3, '0')\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_m = read_pfb(f'{directory_out}/SM.1999.daily.161.pfb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_m[4,27,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_storage = read_pfb(f'{directory_out}/SUBstorage.1999.daily.161.pfb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_storage.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_wat_stor = read_pfb(f'{directory_out}/SURF_WATstorage.1999.daily.161.pfb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf_wat_stor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterTableDepth = read_pfb(f'{directory_out}/WTD.1999.daily.161.pfb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterTableDepth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: qflx_evap_tot for total evaporation [mm/s]\n",
    "qflx_evap_CLM = np.zeros((5, ny, nx))\n",
    "for i in range(5):    \n",
    "    print(f'reading file {i}')\n",
    "    CLM_file = read_pfb(f'{path_outputs}/{runname}.out.clm_output.{str(i+1).zfill(5)}.C.pfb')\n",
    "    CLM_file[CLM_file<-9000] = 0 # set values outside of the domain to zero\n",
    "    qflx_evap_CLM[i, ...] = CLM_file[4,...] # fill qflx_evap_CLM array by flagging the 4 position in the CLM file for qflx_evap_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ET from mm/s to mm/h\n",
    "qflx_evap_CLM = qflx_evap_CLM*3600\n",
    "qflx_evap_CLM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the first timestep at a location for qflx_evap\n",
    "qflx_evap_CLM[0,2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the first timestep at a location\n",
    "day1_ET = np.squeeze(read_pfb(f'{directory_out}/ET.2003.daily.001.pfb'))\n",
    "day1_ET[9,2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumET = day1_ET.sum(axis=0)\n",
    "sumET.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumET[2000:2005,2000:2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
